{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data_folder = \"../data\"\n",
    "\n",
    "\n",
    "def read_metadata(data_folder):\n",
    "    all_data = []\n",
    "\n",
    "    for subdir in sorted(os.listdir(data_folder)):\n",
    "        subdir_path = os.path.join(data_folder, subdir)\n",
    "\n",
    "        if os.path.isdir(subdir_path):\n",
    "            metadata_file = os.path.join(subdir_path, \"metadata.json\")\n",
    "\n",
    "            if os.path.exists(metadata_file):\n",
    "                with open(metadata_file, \"r\") as f:\n",
    "                    metadata = json.load(f)\n",
    "\n",
    "                    for snapshot in metadata.get(\"snapshots\", []):\n",
    "                        all_data.append({\n",
    "                            \"subdir\": subdir,\n",
    "                            \"image_file\": snapshot.get(\"filename\", \"\"),\n",
    "                            \"x\": snapshot.get(\"x\", 0),\n",
    "                            \"y\": snapshot.get(\"y\", 0),\n",
    "                            \"theta\": snapshot.get(\"theta\", 0)\n",
    "                        })\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def get_full_path(row):\n",
    "    image_path_in_subdir = os.path.join(row[\"subdir\"], row[\"image_file\"])\n",
    "    return os.path.join(data_folder, image_path_in_subdir)\n",
    "\n",
    "\n",
    "data = read_metadata(data_folder)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "output_file = \"data/compiled_metadata.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Metadata compiled and saved to {output_file}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54fbb7475cb9d2de",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"data/compiled_metadata.csv\")\n",
    "df[\"full_path\"] = df.apply(lambda row: os.path.join(data_folder, row[\"subdir\"], row[\"image_file\"]), axis=1)\n",
    "missing_images_count = sum(~df[\"full_path\"].apply(os.path.exists))\n",
    "print(f\"Number of missing images: {missing_images_count}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47d8fcf6adf56645",
   "metadata": {},
   "source": [
    "background_img = mpimg.imread(\"assets/gametable.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a135c52ce8887bd2",
   "metadata": {},
   "source": [
    "image_height, image_width, _ = background_img.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21a17da13a1635c4",
   "metadata": {},
   "source": [
    "len(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ceccf03c7527628c",
   "metadata": {},
   "source": [
    "def plot_scatter_plot(dataframe):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(background_img, extent=[0, image_width, image_height, 0], aspect='auto', alpha=0.9)\n",
    "    plt.scatter(dataframe[\"x\"], dataframe[\"y\"], alpha=0.2, s=15, c=\"darkblue\")\n",
    "    plt.xlim(0, image_width)\n",
    "    plt.ylim(image_height, 0)\n",
    "    plt.xlabel(\"X Position\")\n",
    "    plt.ylabel(\"Y Position\")\n",
    "    plt.title(\"Scatter Plot of (x, y) Positions\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_scatter_plot(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b234107b33e9d9c",
   "metadata": {},
   "source": [
    "def plot_density(df):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(background_img, extent=[0, image_width, image_height, 0], aspect='auto', alpha=0.8)\n",
    "\n",
    "    ax = sns.kdeplot(x=df[\"x\"], y=df[\"y\"], cmap=\"magma\", fill=True, alpha=0.8)\n",
    "\n",
    "    plt.xlim(0, image_width)\n",
    "    plt.ylim(image_height, 0)\n",
    "    plt.xlabel(\"X Position\")\n",
    "    plt.ylabel(\"Y Position\")\n",
    "\n",
    "    cbar = plt.colorbar(ax.collections[0], label=\"Density\")\n",
    "\n",
    "    plt.title(\"Density Heatmap of (x, y) Positions\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.0)\n",
    "    plt.show()\n",
    "\n",
    "plot_density(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9106c8b61da439fb",
   "metadata": {},
   "source": [
    "so.Plot(data=df, x=\"x\").add(so.Bars(), so.Hist(bins=50))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7c0cbf8e641536e1",
   "metadata": {},
   "source": [
    "so.Plot(data=df, x=\"y\").add(so.Bars(), so.Hist(bins=50))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52048a26b6797034",
   "metadata": {},
   "source": [
    "so.Plot(data=df, x=\"theta\").add(so.Bars(), so.Hist(bins=50))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1bfa375ac92a442a",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def clean_df_by_density(df, grid_size=5, max_points_per_cell=1):\n",
    "    x_min, x_max = df['x'].min(), df['x'].max()\n",
    "    y_min, y_max = df['y'].min(), df['y'].max()\n",
    "\n",
    "    x_bins = np.arange(x_min, x_max + grid_size, grid_size)\n",
    "    y_bins = np.arange(y_min, y_max + grid_size, grid_size)\n",
    "\n",
    "    df['x_bin'] = np.digitize(df['x'], x_bins) - 1\n",
    "    df['y_bin'] = np.digitize(df['y'], y_bins) - 1\n",
    "    df['cell'] = list(zip(df['x_bin'], df['y_bin']))\n",
    "\n",
    "    sampled_indices = []\n",
    "    grouped = df.groupby('cell')\n",
    "    for cell, group in grouped:\n",
    "        if len(group) <= max_points_per_cell:\n",
    "            sampled_indices.extend(group.index.tolist())\n",
    "        else:\n",
    "            sampled_indices.extend(group.index[:max_points_per_cell])\n",
    "\n",
    "    cleaned_df = df.loc[sampled_indices].copy()\n",
    "    cleaned_df = cleaned_df.drop(columns=['x_bin', 'y_bin', 'cell'])\n",
    "\n",
    "    cleaned_df.reset_index(drop=True, inplace=True)\n",
    "    cleaned_df.to_csv(\"data/cleaned_metadata.csv\", index=False)\n",
    "\n",
    "    print(f\"Original size: {len(df)}, Cleaned size: {len(cleaned_df)}\")\n",
    "    return cleaned_df\n",
    "\n",
    "cleaned_df = clean_df_by_density(df, grid_size=3, max_points_per_cell=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1a6fa6a952542fb",
   "metadata": {},
   "source": [
    "plot_scatter_plot(cleaned_df)\n",
    "plot_density(cleaned_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_density_comparison(df_uncleaned, df_cleaned):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    title_fontsize = 16\n",
    "    label_fontsize = 14\n",
    "    tick_fontsize = 12\n",
    "    cbar_fontsize = 14\n",
    "\n",
    "    axes[0].imshow(background_img, extent=[0, image_width, image_height, 0], aspect='auto', alpha=0.8)\n",
    "    sns.kdeplot(x=df_uncleaned[\"x\"], y=df_uncleaned[\"y\"], cmap=\"magma\", fill=True, alpha=0.8, ax=axes[0])\n",
    "    axes[0].set_xlim(0, image_width)\n",
    "    axes[0].set_ylim(300, 100)\n",
    "    axes[0].set_title(\"Uncleaned Data Density\", fontsize=title_fontsize)\n",
    "    axes[0].set_xlabel(\"X Position\", fontsize=label_fontsize)\n",
    "    axes[0].set_ylabel(\"Y Position\", fontsize=label_fontsize)\n",
    "    axes[0].tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "    axes[1].imshow(background_img, extent=[0, image_width, image_height, 0], aspect='auto', alpha=0.8)\n",
    "    kde_plot = sns.kdeplot(x=df_cleaned[\"x\"], y=df_cleaned[\"y\"], cmap=\"magma\", fill=True, alpha=0.8, ax=axes[1])\n",
    "    axes[1].set_xlim(0, image_width)\n",
    "    axes[1].set_ylim(300, 100)\n",
    "    axes[1].set_title(\"Cleaned Data Density\", fontsize=title_fontsize)\n",
    "    axes[1].set_xlabel(\"X Position\", fontsize=label_fontsize)\n",
    "    axes[1].set_ylabel(\"Y Position\", fontsize=label_fontsize)\n",
    "    axes[1].tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "    cbar = fig.colorbar(kde_plot.collections[0], ax=axes, orientation='vertical', fraction=0.05, pad=0.02)\n",
    "    cbar.ax.set_ylabel(\"Probability Density\", fontsize=cbar_fontsize)\n",
    "    cbar.ax.tick_params(labelsize=tick_fontsize)\n",
    "\n",
    "    plt.suptitle(\"Density Heatmap Comparison: Uncleaned vs Cleaned Data\", fontsize=title_fontsize + 2, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "plot_density_comparison(df, cleaned_df)"
   ],
   "id": "ac84b565a023c675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cleaned_df[\"x\"].min() - cleaned_df[\"x\"].max(), cleaned_df[\"y\"].min() - cleaned_df[\"y\"].max(),",
   "id": "6cdeec5e28dddef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d2199dfaea816e71",
   "metadata": {},
   "source": [
    "cleaned_df[\"x\"] = (cleaned_df[\"x\"] - cleaned_df[\"x\"].mean()) / cleaned_df[\"x\"].std()\n",
    "cleaned_df[\"y\"] = (cleaned_df[\"y\"] - cleaned_df[\"y\"].mean()) / cleaned_df[\"y\"].std()\n",
    "cleaned_df[\"theta\"] = (cleaned_df[\"theta\"] - cleaned_df[\"theta\"].mean()) / cleaned_df[\"theta\"].std()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9ddf7974a9914a",
   "metadata": {},
   "source": [
    "so.Plot(data=cleaned_df, x='x', y='y').add(so.Dots())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34a16dae9366447a",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def plot_random_images_grid(df, grid_size=(3, 3)):\n",
    "    sample_data = df.sample(n=min(grid_size[0] * grid_size[1], len(df)))\n",
    "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(12, 12))\n",
    "\n",
    "    for ax, (_, sample) in zip(axes.flat, sample_data.iterrows()):\n",
    "        path = get_full_path(sample)\n",
    "        if os.path.exists(path):\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (160, 120))\n",
    "                ax.imshow(img, cmap='gray')\n",
    "                ax.set_title(f\"x: {sample['x']:.3f}, y: {sample['y']:.3f}, Î¸: {sample['theta']:.3f}\", fontsize=8)\n",
    "            else:\n",
    "                ax.set_title(\"Failed to Load\", fontsize=8)\n",
    "        else:\n",
    "            print(f\"Image not found: {path}\")\n",
    "            ax.set_title(\"Image Not Found\", fontsize=8)\n",
    "\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_random_images_grid(cleaned_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85cbea7a08aa60fd",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (160, 120))\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "X = np.array([load_image(path) for path in df[\"full_path\"]])\n",
    "\n",
    "X = X.reshape(X.shape[0], 120, 160, 1)\n",
    "\n",
    "y = df[[\"x\", \"y\", \"theta\"]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e7f50b0e109d023c",
   "metadata": {},
   "source": [
    "from keras.src.losses import Huber\n",
    "\n",
    "huber_loss = Huber(delta=1.0)\n",
    "\n",
    "y_random_train = np.random.uniform(y_train.min(), y_train.max(), size=(len(y_train), 3))\n",
    "train_score = huber_loss(y_train, y_random_train).numpy()\n",
    "\n",
    "train_score\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.shape",
   "id": "1040c400dd5c45a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d42113595eb672f8",
   "metadata": {},
   "source": [
    "from keras.src.layers import SeparableConv2D, GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n",
    "from keras.src.layers import MaxPooling2D, Flatten\n",
    "from keras import Sequential, Input\n",
    "\n",
    "model = Sequential([\n",
    "    Input((120, 160, 1)),\n",
    "\n",
    "    SeparableConv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2,2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    SeparableConv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2,2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    SeparableConv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2,2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='linear')\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "911a8424dda8eab",
   "metadata": {},
   "source": [
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2ddf0455ce1c747",
   "metadata": {},
   "source": [
    "from keras.src.optimizers.schedules import CosineDecayRestarts\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from keras.src.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.src.optimizers import Adam\n",
    "from keras.src.losses import Huber\n",
    "\n",
    "checkpoint_folder = \"ckpt\"\n",
    "os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "batch_size = 128\n",
    "\n",
    "batches_per_epoch = len(X_train) // batch_size\n",
    "first_decay_steps = 5 * batches_per_epoch\n",
    "\n",
    "sgdr_scheduler = CosineDecayRestarts(\n",
    "    initial_learning_rate=0.01,\n",
    "    first_decay_steps=first_decay_steps,\n",
    "    t_mul=2.0,\n",
    "    m_mul=0.5,\n",
    "    alpha=1e-5\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=sgdr_scheduler)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=Huber(delta=1.0))\n",
    "\n",
    "log_path_file = \"logs/latest_run_path.txt\"\n",
    "if os.path.exists(log_path_file):\n",
    "    with open(log_path_file, \"r\") as f:\n",
    "        log_dir = f.read().strip()\n",
    "else:\n",
    "    log_dir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    with open(log_path_file, \"w\") as f:\n",
    "        f.write(log_dir)\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "\n",
    "latest_checkpoint = os.path.join(checkpoint_folder, \"latest.keras\")\n",
    "best_checkpoint = os.path.join(checkpoint_folder, \"best.keras\")\n",
    "\n",
    "latest_checkpoint_callback = ModelCheckpoint(\n",
    "    latest_checkpoint, monitor=\"val_loss\", save_best_only=False, save_weights_only=False, verbose=1\n",
    ")\n",
    "\n",
    "best_checkpoint_callback = ModelCheckpoint(\n",
    "    best_checkpoint, monitor=\"val_loss\", save_best_only=True, save_weights_only=False, verbose=1\n",
    ")\n",
    "\n",
    "initial_epoch = 0\n",
    "if os.path.exists(latest_checkpoint):\n",
    "    print(\"Loading previous model state...\")\n",
    "    model = tf.keras.models.load_model(latest_checkpoint)\n",
    "    with open(os.path.join(checkpoint_folder, \"epoch.txt\"), \"r\") as f:\n",
    "        initial_epoch = int(f.read().strip())\n",
    "    print(f\"Resuming training from epoch {initial_epoch}\")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=Huber(delta=1.0))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d92e2b8b0dcc82ee",
   "metadata": {},
   "source": [
    "epochs = 500\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    initial_epoch=initial_epoch,\n",
    "    callbacks=[tensorboard_callback, latest_checkpoint_callback, best_checkpoint_callback],\n",
    "    verbose=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22f733b121cdee50",
   "metadata": {},
   "source": [
    "model.save(latest_checkpoint)\n",
    "\n",
    "with open(os.path.join(checkpoint_folder, \"epoch.txt\"), \"w\") as f:\n",
    "    f.write(str(epochs))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc0c4c3ab9f542a5",
   "metadata": {},
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"pose_estimator.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.src.saving import load_model\n",
    "\n",
    "model = load_model(best_checkpoint)"
   ],
   "id": "1d73f67e5dca83d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred * cleaned_df[[\"x\", \"y\", \"theta\"]].std().values) + cleaned_df[[\"x\", \"y\", \"theta\"]].mean().values\n",
    "y_test = (y_test * cleaned_df[[\"x\", \"y\", \"theta\"]].std().values) + cleaned_df[[\"x\", \"y\", \"theta\"]].mean().values\n"
   ],
   "id": "fbec9914d83ee55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_pred",
   "id": "7b7f288f4bca6ffd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_test",
   "id": "3220c1106b146ffe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "points = 10\n",
    "arrow_length = 10\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.imshow(background_img, extent=[0, image_width, image_height, 0], aspect='auto', alpha=0.9)\n",
    "\n",
    "plt.scatter(y_pred[:points, 0], y_pred[:points, 1], alpha=0.7, s=100, c='red', label='Predicted')\n",
    "plt.scatter(y_test[:points, 0], y_test[:points, 1], alpha=0.7, s=100, c='blue', label='Actual')\n",
    "\n",
    "for i in range(points):\n",
    "    plt.plot([y_test[i, 0], y_pred[i, 0]], [y_test[i, 1], y_pred[i, 1]], 'k--', alpha=0.6)\n",
    "\n",
    "    dx_pred = arrow_length * np.cos(y_pred[i, 2])\n",
    "    dy_pred = arrow_length * np.sin(y_pred[i, 2])\n",
    "    plt.arrow(y_pred[i, 0], y_pred[i, 1], dx_pred, dy_pred, head_width=5, head_length=5, fc='green', ec='green')\n",
    "\n",
    "    dx_test = arrow_length * np.cos(y_test[i, 2])\n",
    "    dy_test = arrow_length * np.sin(y_test[i, 2])\n",
    "    plt.arrow(y_test[i, 0], y_test[i, 1], dx_test, dy_test, head_width=5, head_length=5, fc='green', ec='green')\n",
    "\n",
    "plt.xlim(0, image_width)\n",
    "plt.ylim(image_height, 0)\n",
    "\n",
    "plt.xlabel(\"X Position\")\n",
    "plt.ylabel(\"Y Position\")\n",
    "plt.title(\"Scatter Plot of (x, y) Prediction vs Actual\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ],
   "id": "dafe984fa9b6d6f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from math import sqrt\n",
    "\n",
    "mse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Mean Squared Error: {mse:.3f}\")"
   ],
   "id": "6181b9deb5c8925d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
