{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from keras.src.saving import load_model\n",
    "\n",
    "model = load_model(\"data/ckpt/best.keras\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.data_loader import load_dataframe, create_datasets, denormalize_labels\n",
    "\n",
    "df = load_dataframe(\"data/cleaned_metadata.csv\")\n",
    "\n",
    "train_dataset, test_dataset = create_datasets(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    batch_size=128,\n",
    "    augment_fn=None\n",
    ")"
   ],
   "id": "75d7bf852ea188c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%env TF_USE_LEGACY_KERAS=0",
   "id": "b3d98e3235057af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def representative_data_gen():\n",
    "    for data, _ in test_dataset.take(100):\n",
    "        yield [data]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_int8_model = converter.convert()\n",
    "\n",
    "output_path = \"data/ckpt/best_int8.tflite\"\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(tflite_int8_model)\n",
    "\n",
    "print(f\"Model saved at: {output_path}\")"
   ],
   "id": "2e135bc10d25e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "output_path = \"data/ckpt/best.tflite\"\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model successfully converted to TFLite and saved as 'best.tflite'\")"
   ],
   "id": "b15cc87dba52ed58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test Inference API",
   "id": "bca92af553bb7352"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "URL = \"http://192.168.31.242:5000\"\n",
    "\n",
    "def send_image(image_path):\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        files = {'image': img_file}\n",
    "        response = requests.post(f\"{URL}/predict\", files=files)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"Prediction:\", result['prediction'])\n",
    "        print(\"Inference Time (seconds):\", result['inference_time_seconds'])\n",
    "        return result['prediction']\n",
    "    else:\n",
    "        print(\"Error:\", response.json())\n",
    "\n",
    "for (Xs, ys) in test_dataset.take(1):\n",
    "    X, y = Xs[0] * 255, ys[0]\n",
    "    print(denormalize_labels(y))\n",
    "    print(X.shape)\n",
    "    image_path = \"test_image.jpg\"\n",
    "    big_model_pred = model.predict(Xs)[0]\n",
    "    grayscale_array_squeezed = np.squeeze(X, axis=2)\n",
    "    print(grayscale_array_squeezed.shape)\n",
    "    Image.fromarray(grayscale_array_squeezed.astype(np.uint8), mode=\"L\").save(image_path)\n",
    "    print(\"Quantised predictions\", denormalize_labels(send_image('test_image.jpg')))\n",
    "    print(\"Best model predictions\", denormalize_labels(big_model_pred))\n",
    "    print(\"Real values\", denormalize_labels(y).numpy())\n"
   ],
   "id": "640af0c16809d08a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "URL = \"http://192.168.31.242:5000\"\n",
    "\n",
    "def send_image(image_path):\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        files = {'image': img_file}\n",
    "        response = requests.post(f\"{URL}/predict\", files=files)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result['prediction'], result['inference_time_seconds']\n",
    "    else:\n",
    "        print(\"Error:\", response.json())\n",
    "        return None, None\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return mse, rmse\n",
    "\n",
    "big_model_preds = []\n",
    "quantized_preds = []\n",
    "real_values = []\n",
    "inference_times = []\n",
    "\n",
    "for Xs, ys in tqdm(test_dataset, desc=\"Processing test samples\"):\n",
    "    for X, y in zip(Xs, ys):\n",
    "        X, y = X * 255, y\n",
    "        real_values.append(denormalize_labels(y).numpy())\n",
    "\n",
    "        image_path = \"test_image.jpg\"\n",
    "        grayscale_array_squeezed = np.squeeze(X, axis=2)\n",
    "        Image.fromarray(grayscale_array_squeezed.astype(np.uint8), mode=\"L\").save(image_path)\n",
    "\n",
    "        big_model_pred = model.predict(np.expand_dims(X / 255, axis=0))[0]\n",
    "        big_model_preds.append(denormalize_labels(big_model_pred))\n",
    "\n",
    "        quant_pred, inference_time = send_image(image_path)\n",
    "        quantized_preds.append(denormalize_labels(np.array(quant_pred)))\n",
    "        inference_times.append(inference_time)"
   ],
   "id": "3229545c1fffd29d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'Big model predictions: {np.array(big_model_preds).shape}')\n",
    "print(f'Quantized model predictions: {np.array(quantized_preds).shape}')\n",
    "quantized_preds = np.reshape(np.array(quantized_preds), (-1, 3))\n",
    "mse_big, rmse_big = calculate_metrics(real_values, big_model_preds)\n",
    "mse_quant, rmse_quant = calculate_metrics(real_values, quantized_preds)\n",
    "avg_inference_time = np.mean(inference_times)\n",
    "\n",
    "print(\"\\nComparison Metrics:\")\n",
    "print(f\"Big Model - MSE: {mse_big:.4f}, RMSE: {rmse_big:.4f}\")\n",
    "print(f\"Quantized Model - MSE: {mse_quant:.4f}, RMSE: {rmse_quant:.4f}\")\n",
    "print(f\"Average Inference Time (Quantized Model): {avg_inference_time:.4f} seconds\")"
   ],
   "id": "95861a514a6ce097",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
